# Activity Summary for 10/14/2025

## 4:50:40 PM
A new Architecture Decision Record (ADR) file, `/Users/mmuruts/projects/tink/transaction-service/docs/adr/mv/cassandra-v1-to-v2-migration.md`, was added/modified on October 14, 2025, at 4:04:50 PM. This document outlines a comprehensive strategy for migrating data from a Cassandra V1 cluster (`bigdb`) to a separate Cassandra V2 cluster (`bigdbt`).

The core challenge highlighted is the cross-cluster nature of this migration, explicitly stating that Cassandra materialized views **cannot** be used for this purpose, despite a reference CQL script for materialized views being included.

Key changes and information detailed in the document include:

*   **Schema Evolution**: The V1 schema (`transactions_by_userid_period`) includes legacy fields, `exactamount`, various date/time fields, `inserted` and `timestamp` as bigints, user modification flags, and serialized payloads. The V2 schema (`transactions_by_userid_period_YYYYQ`) is streamlined, featuring a single `amount` field, combined datetime fields (`bookeddatetime`, `valuedatetime`), new fields like `status`, `source`, `metadata`, and renamed merchant fields, while omitting category-related, user modification, and serialized payload fields.
*   **Field Mappings**: The document provides extensive mappings, categorizing them into:
    *   **Direct Mappings**: Fields like `userid`, `id`, `accountid`, `description`, `exactamount` (to `amount`), and many merchant address fields retain their names or have direct equivalents.
    *   **Derived/Default Mappings**: Fields like `merchantid` are converted to `merchantnationalid`, `providerexternalid` acts as a fallback for `externalid`, `status` defaults to 'ACTIVE', `inserted` (bigint) is converted to a timestamp, and `source` defaults to 'V1_MIGRATION'.
    *   **Fields Not Migrated**: Numerous V1-only fields are explicitly listed as not being carried over to V2, including `categoryid`, `credentialsid`, `exactoriginalamount`, various `usermodified*` flags, and all `*serialized` payload fields.
*   **Migration Strategy Options**: Three options are proposed:
    *   **Option 1 (Recommended)**: A Go-based batch migration tool, designed for historical data. It reads from V1, transforms, and writes to V2. This option offers full control and integration with existing Go codebase, though it may be slower than Spark for very large datasets.
    *   **Option 2**: Application Dual-Write, suitable for ongoing data. The application writes new transactions to both V1 and V2, ensuring no data loss during cutover. This leverages existing application infrastructure.
    *   **Option 3**: Spark-Based ETL, recommended for massive datasets (over 1 billion transactions) due to its parallelism and fault tolerance.
*   **Implementation and Operational Details**: The document covers implementation notes (though referencing materialized views despite the initial warning about cross-cluster limitations), usage steps (running migration, verification, updating application), monitoring metrics (MV build progress, replication lag), and a comprehensive rollback plan.

The document serves as a critical guide for a complex database migration, emphasizing the need for external tooling due to the physical separation of the Cassandra clusters.